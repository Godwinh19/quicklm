BigramLanguageModel_model_at_560_L1_33: {'bs': 64, 'blsz': 256, 'max_iters': 3370, 'lr': 0.0003, 'n_embd': 384, 'n_head': 6, 'n_layer': 6, 'drop': 0.2}
BigramLanguageModel_model_at_565_L1_31: {'bs': 64, 'blsz': 256, 'max_iters': 3370, 'lr': 0.0003, 'n_embd': 384, 'n_head': 6, 'n_layer': 6, 'drop': 0.2}
GPT_model_at_300_L2_79: {'bs': 64, 'blsz': 256, 'gamma': 0.1, 'step_size': 50, 'lr_step_size': 60, 'max_iters': 3000, 'lr': 0.0003, 'n_embd': 384, 'n_head': 6, 'n_layer': 6, 'drop': 0.1, 'ffwd_dim': None} 
